<!DOCTYPE html>
<html lang="en-us">

<head>

<script async src="https://www.googletagmanager.com/gtag/js?id=UA-108705746-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-108705746-1');
</script>


<style type="text/css">
img[src$='#floatcenter']
{
display: block;
margin: 0.7rem auto;
}
</style>
<script type="text/javascript" async
  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML">
</script>
<meta charset="utf-8">
<meta charset="EUC-KR">
<meta http-equiv="X-UA-Compatible" content="chrome=1">
<meta name="HandheldFriendly" content="True">
<meta name="MobileOptimized" content="320">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="referrer" content="no-referrer">
<meta name="description" content="Taeoh Kim&#39;s Personal Blog">
<base href="https://taeoh-kim.github.io/">
<title>


     Tensorflow로 50줄짜리 Original GAN Code 구현하기 

</title>
<link rel="canonical" href="https://taeoh-kim.github.io/blog/tensorflow%EB%A1%9C-50%EC%A4%84%EC%A7%9C%EB%A6%AC-original-gan-code-%EA%B5%AC%ED%98%84%ED%95%98%EA%B8%B0/">







<link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.6.0/styles/default.min.css">
    <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.6.0/highlight.min.js"></script>
    <script>hljs.initHighlightingOnLoad();</script>



<script type="text/javascript" src="https://ajax.googleapis.com/ajax/libs/jquery/2.1.3/jquery.min.js"></script>


<link rel="stylesheet" href="//maxcdn.bootstrapcdn.com/font-awesome/4.5.0/css/font-awesome.min.css">
<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,700|Ubuntu+Mono:400,400i,700,700i|Raleway:500|Work+Sans">



    
    <link rel="stylesheet" href="https://taeoh-kim.github.io/css/light-style.css?t=1558077679">
    




<link rel="shortcut icon"

    href="https://taeoh-kim.github.io/img/fav.ico"

>








</head>

<body lang="en">
  


<div class="section" id="top">

    <div class="container hero  fade-in one ">
    <h2 class="bold-title is-1">Taeoh Kim's Blog</h2>
    </div>


<div class="section  fade-in two ">

    <div class="container">
    <hr>
<nav class="nav nav-center">
    <span id="nav-toggle" class="nav-toggle"  onclick="document.getElementById('nav-menu').classList.toggle('is-active');">
      <span></span>
      <span></span>
      <span></span>
    </span>
    <div id="nav-menu" class="nav-left nav-menu">
      <span class="nav-item">
        <a href="https://taeoh-kim.github.io/">Main</a>
      </span>
      <span class="nav-item">
        <a href="https://taeoh-kim.github.io/#about">About</a> 
      </span>
    
    
      <span class="nav-item">
        <a href="https://taeoh-kim.github.io/#blog">Back to blog</a> 
      </span>
    
      <span class="nav-item">
        <a href="https://taeoh-kim.github.io/#contact">Contact</a>
      </span>
    
      <span class="nav-item">
        <a href="https://taeoh-kim.github.io/index.xml"><i class="fa fa-rss"></i></a>
      </span>
    
    </div>
</nav>
<hr>
    </div>

    <div class="container  fade-in two ">
        <h2 class="title is-1 top-pad strong-post-title"><a href="https://taeoh-kim.github.io/blog/tensorflow%EB%A1%9C-50%EC%A4%84%EC%A7%9C%EB%A6%AC-original-gan-code-%EA%B5%AC%ED%98%84%ED%95%98%EA%B8%B0/">Tensorflow로 50줄짜리 Original GAN Code 구현하기</a></h2>
            <div class="post-data">
                Aug 10, 2017 |
                5 minutes read
            </div>

            
                <div class="blog-share">
                Share this:
                <a class="twitter-share-button" href="https://twitter.com/intent/tweet?text=Read%20Tensorflow%eb%a1%9c%2050%ec%a4%84%ec%a7%9c%eb%a6%ac%20Original%20GAN%20Code%20%ea%b5%ac%ed%98%84%ed%95%98%ea%b8%b0%20https%3a%2f%2ftaeoh-kim.github.io%2fblog%2ftensorflow%25EB%25A1%259C-50%25EC%25A4%2584%25EC%25A7%259C%25EB%25A6%25AC-original-gan-code-%25EA%25B5%25AC%25ED%2598%2584%25ED%2595%2598%25EA%25B8%25B0%2f"
                onclick="window.open(this.href, 'twitter-share', 'width=550,height=235');return false;">
                <i class="fa fa-twitter"></i>
                <span class="hidden">Twitter</span>
                </a>
                <a class="icon-facebook" href="https://www.facebook.com/sharer/sharer.php?u=https%3a%2f%2ftaeoh-kim.github.io%2fblog%2ftensorflow%25EB%25A1%259C-50%25EC%25A4%2584%25EC%25A7%259C%25EB%25A6%25AC-original-gan-code-%25EA%25B5%25AC%25ED%2598%2584%25ED%2595%2598%25EA%25B8%25B0%2f"
                onclick="window.open(this.href, 'facebook-share','width=580,height=296');return false;">
                <i class="fa fa-facebook"></i>
                <span class="hidden">Facebook</span>
                </a>
                <a class="icon-pinterest" href="http://pinterest.com/pin/create/button/?url=https%3a%2f%2ftaeoh-kim.github.io%2fblog%2ftensorflow%25EB%25A1%259C-50%25EC%25A4%2584%25EC%25A7%259C%25EB%25A6%25AC-original-gan-code-%25EA%25B5%25AC%25ED%2598%2584%25ED%2595%2598%25EA%25B8%25B0%2f&amp;description=Tensorflow%eb%a1%9c%2050%ec%a4%84%ec%a7%9c%eb%a6%ac%20Original%20GAN%20Code%20%ea%b5%ac%ed%98%84%ed%95%98%ea%b8%b0"
                onclick="window.open(this.href, 'pinterest-share','width=580,height=296');return false;">
                <i class="fa fa-pinterest"></i>
                <span class="hidden">Pinterest</span>
                </a>
                <a class="icon-google-plus" href="https://plus.google.com/share?url=https%3a%2f%2ftaeoh-kim.github.io%2fblog%2ftensorflow%25EB%25A1%259C-50%25EC%25A4%2584%25EC%25A7%259C%25EB%25A6%25AC-original-gan-code-%25EA%25B5%25AC%25ED%2598%2584%25ED%2595%2598%25EA%25B8%25B0%2f"
                onclick="window.open(this.href, 'google-plus-share', 'width=490,height=530');return false;">
                <i class="fa fa-linkedin"></i>
                <span class="hidden">Google+</span>
                </a>
                </div>
            

    </div>

    <div class="container markdown  fade-in two  top-pad">
        

<h2 id="cvml-post-3">CVML Post 3</h2>

<h3 id="gan-implementation-in-50-lines-of-tensorflow-code">GAN Implementation in 50 Lines of Tensorflow Code</h3>

<p><br><br></p>

<p>코드는 <a href="https://github.com/HyeongminLEE/GANin50lines">이형민군의 깃허브 코드</a>를 참조하였습니다. 맨 처음 GAN을 공부하실 때 도움이 될 것으로 희망합니다.
Pytorch 코드는 <a href="https://medium.com/@devnag/generative-adversarial-networks-gans-in-50-lines-of-code-pytorch-e81b79659e3f">여기</a>를 참조하세요.</p>

<p>우선 Full-code는 맨 아래에서 정리하도록 하겠습니다.</p>

<p><br></p>

<h3 id="1-gan-easy-review">1. GAN Easy Review</h3>

<p><br></p>

<p>여기서는 이론적인 내용은 전혀 없으며 100% 구현 중심의 설명이다.
GAN을 간단하게만 Review해 보면, 결국 다음 두 Network를 정의한다.</p>

<ul>
<li>Noise z를 받아서 Fake Data를 만드는 Generator</li>
<li>Real Data와 Fake Data를 구분하는 Discriminator</li>
</ul>

<p>결국 중요한 것은 Loss Function과 Training 방법일 것이다.</p>

<p>Loss Function을 정의하기 전에, 우선 Loss라는 것은 어떠한 System이 있을 때, 그것의 최종 결과물 (혹은 중간 결과물)을 기반으로 설정해주는 것이다.</p>

<p>여기서는 System의 최종 결과물은 Discriminator가 내뱉는 넌 진짜야, 넌 가짜야 하는 것인데.</p>

<ul>
<li>진짜 = Real Data = 1</li>
<li>가짜 = Fake Data = 0</li>
</ul>

<p>으로 정의한다. 0과 1 사이의 값이기 때문에 Cross Entropy로 Loss를 정의하면 되겠다라고 생각해야 한다. (머신러닝 기초를 공부한 사람이라면!)</p>

<p>그렇다면 본 System을 구성하는 Generator와 Discriminator의 Loss는 다음과 같이 된다.</p>

<ul>
<li>Discriminator는 Real Data와 1 사이의 Loss (= Cross Entropy)</li>
<li>Discriminator는 Fake Data와 0 사이의 Loss (= Cross Entropy)</li>
<li>Generator는 Fake Data와 1 사이의 Loss (= Cross Entropy, 속여야 하니까)</li>
</ul>

<p>그렇다면 Cross Entropy 수식은?</p>

<p>$$ CE(pred, y) = -y \cdot log(pred) - (1 - y) \cdot log(1-pred) $$</p>

<p>y는 실제 값, pred는 Network의 예측 값이다.</p>

<p>이것을 Discriminator에 적용하면 (그냥 대입이다)</p>

<p>$$ D_{Loss}=CE(D(x), 1) + CE(D(G(z)), 0) $$
$$ = -log(D(x))-log(1-D(g(z)) $$</p>

<p>Generator에 적용하면</p>

<p>$$ G_{Loss}=CE(D(G(z)), 1) $$
$$ = -log(D(G(z)) $$</p>

<p>끝이다. 이제 구현하자.</p>

<p><br></p>

<h3 id="2-implementation">2. Implementation</h3>

<p><br></p>

<p>50줄의 전체 코드는 크게 5개의 파트로 나누어진다.</p>

<p><br></p>

<h4 id="2-1-requirements-and-dataset">2.1 Requirements and Dataset</h4>

<p>본 코드는 Matplotlib과 Numpy가 필요하고, Tensorflow에서 제공하는 MNIST Dataset을 사용할 예정이다.</p>

<p>또한 입출력단에 사용되는 Placeholder로는 Image Input X (28x28)과 Noise Z (Dimension은 128을 가정)이 필요하다.</p>

<p>다음은 그 구현이다</p>

<pre><code class="language-python">import tensorflow as tf
import matplotlib.pyplot as plt
import numpy as np
from tensorflow.examples.tutorials.mnist import input_data

mnist = input_data.read_data_sets(&quot;./mnist/data/&quot;, one_hot=True)
X = tf.placeholder(tf.float32, [None, 28 * 28]) # MNIST = 28*28
Z = tf.placeholder(tf.float32, [None, 128]) # Noise Dimension = 128
</code></pre>

<p><br></p>

<h4 id="2-2-generator-network">2.2 Generator Network</h4>

<p>Generator의 입력은 Noise Z이고. Fully-Connected 2-Layer를 지나 Real Image와 똑같은 28x28 Dimension의 출력을 내뱉는다.</p>

<p>Hidden Node 갯수는 256으로 정의한다.</p>

<p>MNIST는 0과 1사이의 흑백 Image이므로, 출력시 Sigmoid를 적용해 준다.</p>

<pre><code class="language-python"># ********* G-Network (Hidden Node # = 256)
G_W1 = tf.Variable(tf.random_normal([128, 256], stddev=0.01))
G_W2 = tf.Variable(tf.random_normal([256, 28 * 28], stddev=0.01))
G_b1 = tf.Variable(tf.zeros([256]))
G_b2 = tf.Variable(tf.zeros([28 * 28]))

def generator(noise_z): # 128 -&gt; 256 -&gt; 28*28
    hidden = tf.nn.relu(tf.matmul(noise_z, G_W1) + G_b1)
    output = tf.nn.sigmoid(tf.matmul(hidden, G_W2) + G_b2)
    return output
</code></pre>

<p><br></p>

<h4 id="2-3-discriminator-network">2.3 Discriminator Network</h4>

<p>Generator의 반대로 보면 된다. 입력은 Image (28x28, 가짜든 진짜든)이고, 출력은 0과 1사이의 스칼라 값이다. 이것이 진짜와 가짜를 결정한다.</p>

<p>그러므로 출력단에 Sigmoid 넣어 주면 된다.</p>

<pre><code class="language-python"># ********* D-Network (Hidden Node # = 256)
D_W1 = tf.Variable(tf.random_normal([28 * 28, 256], stddev=0.01))
D_W2 = tf.Variable(tf.random_normal([256, 1], stddev=0.01))
D_b1 = tf.Variable(tf.zeros([256]))
D_b2 = tf.Variable(tf.zeros([1]))

def discriminator(inputs): # 28*28 -&gt; 256 -&gt; 1
    hidden = tf.nn.relu(tf.matmul(inputs, D_W1) + D_b1)
    output = tf.nn.sigmoid(tf.matmul(hidden, D_W2) + D_b2)
    return output
</code></pre>

<p><br></p>

<h4 id="2-4-generate-fake-image-loss-and-optimization">2.4 Generate Fake Image, Loss and Optimization</h4>

<p>Noise를 Generator에 집어넣어 Fake Image를 만들고. 위에서 정의한 Loss를 그대로 구현하고.</p>

<p>Optimizer로는 Adam을 쓰자.</p>

<p>주의할 점은 Generator와 Discriminator는 서로를 건드리지 않고 별개로 Train된다는 것이다.</p>

<pre><code class="language-python"># ********* Generation, Loss, Optimization
G = generator(Z)

loss_D = -tf.reduce_mean(tf.log(discriminator(X)) + tf.log(1 - discriminator(G)))
loss_G = -tf.reduce_mean(tf.log(discriminator(G)))

train_D = tf.train.AdamOptimizer(learning_rate=0.0002).minimize(loss_D, var_list=[D_W1, D_b1, D_W2, D_b2])
train_G = tf.train.AdamOptimizer(learning_rate=0.0002).minimize(loss_G, var_list=[G_W1, G_b1, G_W2, G_b2])
</code></pre>

<p><br></p>

<h4 id="2-5-training-and-testing">2.5 Training and Testing</h4>

<p>Tensorflow니까 Session을 열고 초기화를 해 준다.</p>

<p>Test시에는 고정된 Input (Noise)가 들어갔을 때 Generated되는 Image를 보고 싶기 때문에 Training Loop 밖에서 만들어 준다 (noise_test).</p>

<p>Epoch는 200번, Batch Size는 100으로 설정한다.</p>

<p>각 Batch마다 Noise를 만들고 Discriminator와 Generator를 번갈아가며 Training하면 Training은 끝이다.</p>

<p>Test과정에서는 noise_test를 Generator에 넣어주고 결과를 Plot하는 것이 전부이다.</p>

<pre><code class="language-python">sess = tf.Session()
sess.run(tf.global_variables_initializer())

# ********* Training and Testing
noise_test = np.random.normal(size=(10, 128)) # 10 = Test Sample Size, 128 = Noise Dimension
for epoch in range(200): # 200 = Num. of Epoch
    for i in range(int(mnist.train.num_examples / 100)): # 100 = Batch Size
        batch_xs, _ = mnist.train.next_batch(100)
	noise = np.random.normal(size=(100, 128))

        sess.run(train_D, feed_dict={X: batch_xs, Z: noise})
        sess.run(train_G, feed_dict={Z: noise})

    if epoch == 0 or (epoch + 1) % 10 == 0: # 10 = Saving Period
        samples = sess.run(G, feed_dict={Z: noise_test})

        fig, ax = plt.subplots(1, 10, figsize=(10, 1))
        for i in range(10):
            ax[i].set_axis_off()
            ax[i].imshow(np.reshape(samples[i], (28, 28)))
        plt.savefig('samples_ex/{}.png'.format(str(epoch).zfill(3)), bbox_inches='tight')
        plt.close(fig)
</code></pre>

<p><br></p>

<h3 id="3-full-code">3. Full Code</h3>

<p><br></p>

<pre><code class="language-python">import tensorflow as tf
import matplotlib.pyplot as plt
import numpy as np
from tensorflow.examples.tutorials.mnist import input_data

mnist = input_data.read_data_sets(&quot;./mnist/data/&quot;, one_hot=True)
X = tf.placeholder(tf.float32, [None, 28 * 28]) # MNIST = 28*28
Z = tf.placeholder(tf.float32, [None, 128]) # Noise Dimension = 128

# ********* G-Network (Hidden Node # = 256)
G_W1 = tf.Variable(tf.random_normal([128, 256], stddev=0.01))
G_W2 = tf.Variable(tf.random_normal([256, 28 * 28], stddev=0.01))
G_b1 = tf.Variable(tf.zeros([256]))
G_b2 = tf.Variable(tf.zeros([28 * 28]))

def generator(noise_z): # 128 -&gt; 256 -&gt; 28*28
    hidden = tf.nn.relu(tf.matmul(noise_z, G_W1) + G_b1)
    output = tf.nn.sigmoid(tf.matmul(hidden, G_W2) + G_b2)
    return output

# ********* D-Network (Hidden Node # = 256)
D_W1 = tf.Variable(tf.random_normal([28 * 28, 256], stddev=0.01))
D_W2 = tf.Variable(tf.random_normal([256, 1], stddev=0.01))
D_b1 = tf.Variable(tf.zeros([256]))
D_b2 = tf.Variable(tf.zeros([1]))

def discriminator(inputs): # 28*28 -&gt; 256 -&gt; 1
    hidden = tf.nn.relu(tf.matmul(inputs, D_W1) + D_b1)
    output = tf.nn.sigmoid(tf.matmul(hidden, D_W2) + D_b2)
    return output

# ********* Generation, Loss, Optimization and Session Init.
G = generator(Z)
loss_D = -tf.reduce_mean(tf.log(discriminator(X)) + tf.log(1 - discriminator(G)))
loss_G = -tf.reduce_mean(tf.log(discriminator(G)))
train_D = tf.train.AdamOptimizer(learning_rate=0.0002).minimize(loss_D, var_list=[D_W1, D_b1, D_W2, D_b2])
train_G = tf.train.AdamOptimizer(learning_rate=0.0002).minimize(loss_G, var_list=[G_W1, G_b1, G_W2, G_b2])

sess = tf.Session()
sess.run(tf.global_variables_initializer())

# ********* Training and Testing
noise_test = np.random.normal(size=(10, 128)) # 10 = Test Sample Size, 128 = Noise Dimension
for epoch in range(200): # 200 = Num. of Epoch
    for i in range(int(mnist.train.num_examples / 100)): # 100 = Batch Size
        batch_xs, _ = mnist.train.next_batch(100)
	noise = np.random.normal(size=(100, 128))

        sess.run(train_D, feed_dict={X: batch_xs, Z: noise})
        sess.run(train_G, feed_dict={Z: noise})

    if epoch == 0 or (epoch + 1) % 10 == 0: # 10 = Saving Period
        samples = sess.run(G, feed_dict={Z: noise_test})

        fig, ax = plt.subplots(1, 10, figsize=(10, 1))
        for i in range(10):
            ax[i].set_axis_off()
            ax[i].imshow(np.reshape(samples[i], (28, 28)))
        plt.savefig('samples_ex/{}.png'.format(str(epoch).zfill(3)), bbox_inches='tight')
        plt.close(fig)
</code></pre>

<p><br></p>

<p>결과는? 사실 썩 만족스러운 결과는 아닐 것이다. 하지만 이 코드는 Tutorial에 불과하고. GAN Original Paper에서 제시하는 Loss와 구현 방식을 그대로 적용한 예제로 보면 될 것 같다.</p>

<p>GAN의 수학적인 안정성에 관심이 많은 사람은 DCGAN을 거쳐 InfoGAN, f-GAN, EBGAN, WGAN, BEGAN, WGAN-GP 등을 보면 될 것 같다.</p>

<p>GAN의 응용 분야에 관심이 많은 사람은 DCGAN, VAE, InfoGAN을 공부한 뒤 Pix2Pix, CycleGAN, DiscoGAN을 보고 다음 포스팅을 참고하면 좋을 것 같다.</p>

    </div>

    <div class="disqus">
        
    </div>

<div class="container has-text-centered top-pad">
<hr>
<a href="https://taeoh-kim.github.io/blog/tensorflow%EB%A1%9C-50%EC%A4%84%EC%A7%9C%EB%A6%AC-original-gan-code-%EA%B5%AC%ED%98%84%ED%95%98%EA%B8%B0/#top"><i class="fa fa-arrow-up"></i></a>
<hr>
</div>

<div class="section" id="footer">
    <div class="container has-text-centered">
        
        <span class="footer-text"><a href="https://github.com/vickylaiio/hugo-theme-introduction" target="_blank">Introduction</a> theme for <a href="http://gohugo.io/" target="_blank">Hugo</a>. Made by Taeoh Kim. <a href="https://vickylai.io" target="_blank">Vicky Lai</a> 2017</span>
        
    </div>
</div>

</div>
</div>


<script>
$('a[href^="https:\/\/taeoh-kim.github.io\/blog\/tensorflow%EB%A1%9C-50%EC%A4%84%EC%A7%9C%EB%A6%AC-original-gan-code-%EA%B5%AC%ED%98%84%ED%95%98%EA%B8%B0\/#"]').click(function(e) {
    e.preventDefault();
    var target = this.hash;
    $('html, body').animate({
    scrollTop: $(target).offset().top
    }, 500);
    return false;
})
</script>

</body>
