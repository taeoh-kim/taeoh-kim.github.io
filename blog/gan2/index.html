<!DOCTYPE html>
<html class="no-js" lang="en-us"><head>

<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta name="description" content="This is meta description">
 <meta name="author" content="TaeohKim">
<meta name="generator" content="Hugo 0.66.0" />
<script type="text/javascript" async
  src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
  MathJax.Hub.Config({
  tex2jax: {
    inlineMath: [['$','$'], ['\\(','\\)']],
    displayMath: [['$$','$$']],
    processEscapes: true,
    processEnvironments: true,
    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
    TeX: { equationNumbers: { autoNumber: "AMS" },
         extensions: ["AMSmath.js", "AMSsymbols.js"] }
  }
  });
  MathJax.Hub.Queue(function() {
    
    
    
    var all = MathJax.Hub.getAllJax(), i;
    for(i = 0; i < all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });

  MathJax.Hub.Config({
  
  TeX: { equationNumbers: { autoNumber: "AMS" } }
  });
</script>


<title>Generative Models Part 2: ImprovedGAN,InfoGAN,EBGAN</title>

<!-- Mobile Specific Meta -->
<meta name="viewport" content="width=device-width, initial-scale=1">

<!-- Favicon -->
<link rel="shortcut icon" type="image/x-icon" href="https://taeoh-kim.github.io/images/favicon.ico" />

<!-- Stylesheets -->
<!-- Themefisher Icon font -->
<link rel="stylesheet" href="https://taeoh-kim.github.io/plugins/themefisher-font/style.css">
<!-- bootstrap.min css -->
<link rel="stylesheet" href="https://taeoh-kim.github.io/plugins/bootstrap/dist/css/bootstrap.min.css">
<!-- Lightbox.min css -->
<link rel="stylesheet" href="https://taeoh-kim.github.io/plugins/lightbox2/dist/css/lightbox.min.css">
<!-- Slick Carousel -->
<link rel="stylesheet" href="https://taeoh-kim.github.io/plugins/slick-carousel/slick/slick.css">
<link rel="stylesheet" href="https://taeoh-kim.github.io/plugins/slick-carousel/slick/slick-theme.css">
<!-- Main Stylesheet -->


<link rel="stylesheet" href="https://taeoh-kim.github.io/css/style.min.css" media="screen">

</head>
<body id="body">
        <!-- Start Preloader -->
<div id="preloader">
    <div class="preloader">
        <div class="sk-circle1 sk-child"></div>
        <div class="sk-circle2 sk-child"></div>
        <div class="sk-circle3 sk-child"></div>
        <div class="sk-circle4 sk-child"></div>
        <div class="sk-circle5 sk-child"></div>
        <div class="sk-circle6 sk-child"></div>
        <div class="sk-circle7 sk-child"></div>
        <div class="sk-circle8 sk-child"></div>
        <div class="sk-circle9 sk-child"></div>
        <div class="sk-circle10 sk-child"></div>
        <div class="sk-circle11 sk-child"></div>
        <div class="sk-circle12 sk-child"></div>
    </div>
</div>
<!-- End Preloader --><!-- Fixed Navigation -->


<section class="header navigation">

    <div class="container">
        <div class="row">
            <div class="col-md-12">
                <nav class="navbar navbar-expand-md">
                    <a class="navbar-brand" href="https://taeoh-kim.github.io/">
                        <img src="https://taeoh-kim.github.io/images/logo_taeoh.png" alt="logo">
                    </a>
                    <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navigation"
                        aria-controls="navigation" aria-expanded="false" aria-label="Toggle navigation">
                        <span class="tf-ion-android-menu"></span>
                    </button>
                    
                    <div id="drapeaux">
                        
                        
                    </div>
                    <div class="collapse navbar-collapse" id="navigation">
                        <ul class="navbar-nav ml-auto">
                            <li class="nav-item">
                                <a class="nav-link"
                                    href="https://taeoh-kim.github.io/">Home</a>
                            </li>
                            
                            
                            <li class="nav-item">
                                <a class="nav-link" href="https://taeoh-kim.github.io/about">About</a>
                            </li>
                            
                            
                            
                            <li class="nav-item">
                                <a class="nav-link" href="https://taeoh-kim.github.io/service">Publications</a>
                            </li>
                            
                            
                            
                            <li class="nav-item">
                                <a class="nav-link" href="https://taeoh-kim.github.io/blog">Blog</a>
                            </li>
                            
                            
                            
                            <li class="nav-item">
                                <a class="nav-link" href="https://taeoh-kim.github.io/contact">Contact</a>
                            </li>
                            
                            
                        </ul>
                    </div>
                </nav>
            </div>
        </div>
    </div>
</section><div id="content">

<section class="blog-single section">
    <div class="container">
        <div class="row">
            <div class="col-md-8 mx-auto">
                <img src="https://taeoh-kim.github.io/img/infogan_title.PNG" class="w-100 mb-3" alt="Post-Image">
                <h2>Generative Models Part 2: ImprovedGAN,InfoGAN,EBGAN</h2>
                <div class="post-meta mb-5">
                    <ul class="list-inline">
                        <li class="list-inline-item">
                            <span>By</span>
                            Taeoh Kim
                        </li>
                        <li class="list-inline-item">
                            <span>at</span>
                            <span>July 27, 2017</span>
                        </li>
                    </ul>
                </div>
                <h2 id="computer-vision-and-machine-learning-study-post-2">Computer Vision and Machine Learning Study Post 2</h2>
<h3 id="generative-models-part-2-improvedganinfoganebgan">Generative Models Part 2: ImprovedGAN/InfoGAN/EBGAN</h3>
<p><br><br></p>
<p>Reference는 다음과 같습니다.</p>
<ul>
<li>Salimans, Tim, et al. &ldquo;Improved techniques for training gans.&rdquo; Advances in Neural Information Processing Systems. 2016.</li>
<li>Chen, Xi, et al. &ldquo;Infogan: Interpretable representation learning by information maximizing generative adversarial nets.&rdquo; Advances in Neural Information Processing Systems. 2016.</li>
<li>Zhao, Junbo, Michael Mathieu, and Yann LeCun. &ldquo;Energy-based generative adversarial network.&rdquo; arXiv preprint arXiv:1609.03126 (2016).</li>
</ul>
<br>
정리에는 다음 자료들이 큰 도움이 되었습니다.
<br>
<ul>
<li><a href="https://github.com/yunjey/pytorch-tutorial">Yunjey의 DCGAN Pytorch Tutorial</a></li>
<li><a href="https://www.slideshare.net/ssuser06e0c5/infogan-interpretable-representation-learning-by-information-maximizing-generative-adversarial-nets-72268213">Takato Horii Slideshare, 김홍배님 번역</a></li>
<li><a href="https://github.com/buriburisuri/ebgan">Github Pytorch Code: buriburisuri</a></li>
<li><a href="https://github.com/wiseodd/generative-models">Github Pytorch Code: Wiseodd</a></li>
<li><a href="https://github.com/AaronYALai/Generative_Adversarial_Networks_PyTorch">Github Pytorch Code: AaronYALai</a></li>
</ul>
<p><br><br></p>
<h3 id="1-introduction">1. Introduction</h3>
<br>
<p>GAN이 수렴하기 힘들고 Training도 힘들다는 것은 많이 알려진 사실이다. GAN 이후 여러 유명한 논문들이 많이 나오게 되었는데, 그 발자취를 공부 겸 계속 따라가 볼 예정이고, 요약 정리 및 구현할 논문의 기준은 우선은 인용 수를 기준으로 어느정도 추려 보았다.</p>
<p>Improved GAN은 Ian Goodfellow가 2저자로 들어가 있는 논문인데, 내용은 그냥 추가로 이것 저것 해보았다 정도이고, 성능도 약간 향상된 정도인 것 같다. 구현에 실패하기도 했고, 논문에 수식적인 전개가 거의 없고 대부분 경험적으로 되어있기 때문에 간단히 서술하고 넘어갈 예정이다. 흥미로웠던 것은 InfoGAN과 EBGAN인데 사실 성능상으로는 InfoGAN이 좀 더 매력적이었다. 하지만 InfoGAN의 이론적 배경은 좀 어렵다. EBGAN은 이론적 배경보다는 새로운 구조를 제시했는데 사실 구현을 잘 못한 것인지 성능은 만족스럽지 못했으나, 향후에 나오는 GAN 모델에서 EBGAN을 베이스로 많이 사용하기에 공부해 보았다.</p>
<p><br><br></p>
<h3 id="2-improved-gan">2. Improved GAN</h3>
<br>
<h4 id="2-1-paper-summary">2-1. Paper Summary</h4>
<br>
<p>Ian Goodfellow가 2저자로 들어가 있는 본 논문의 Contribution을 간단하게 요약하고자 한다. 사실 논문의 대부분의 방법들이 경험적인 방법들이라 수식이 없다. 그래서 성능도 Dramatic한 변화는 없다.</p>
<br>
1. Feature Matching
<p>Discriminator가 단순히 Real과 Fake를 나누는 것이 아니라. Input Data의 통계를 더 유사하게 따라가기를 원하기 때문에, Discriminator의 중간 Activation이 Fake와 Real Input 사이에서 유사하기를 바란다. 따라서 이것을 Generator에 Objective Function으로 부여하는 Idea이다. 수식으로는 다음과 같다.</p>
<p>$$ \left| E_{x \sim p_{data}}f(x) - E_{z \sim p_{z}}f(G(z)) \right| $$</p>
<p>논문에 의하면 시각적 결과는 별 소득이 없었지만. Semi-supervised Learning에서 좋은 성능을 보여줬다고 한다.</p>
<br>
2. Minibatch Discrimination
<p>시각적 결과는 이것이 더 좋은데, 짧게 요약하면. Discriminator에서 구별 할 때 여러 Sample을 같이 보자는 것이다. 여기서 Mode Collapse의 개념이 나오는데, Generator는 Discriminator를 속이는 것이 목적이지 Image를 다양하고 잘 만드는 것이 목적이 아니기 때문에 그쪽으로 특화가 되게 되는데 그 이유가 Sample간의 Dependency가 없기 때문이다. 따라서 여러 Sample을 같이 보게 하자는 것이 핵심 Idea가 되며 실제 구현은 Discriminator의 중간 Layer에서 Batch 단위로 Tensor Combination (코드 구현을 못해서 확실히 이해하지는 않았지만, 논문에서는 Tensor에 곱하는 식으로 표현했지만 Reshape가 아닐까 생각해 본다)을 통해서 다음 Layer로 넘겨주자는 것이다. 스칼라 값으로 넘겨줄 때 Sample 간 Distance가 낮을 수록 높은 값을 (Collapse되지 않도록), 높을 수록 낮은 값(기존 Discriminator처럼)을 전달해주게 된다. 즉 Real과 Fake 판단은 각 Sample별로 하지만 거기에 들어가는 값들은 여러 Sample의 Feature가 동시에 효율적으로 하게 된다.</p>
<p>하지만 Minibatch Discrimination은 Semi-supervised Learning에는 별 소득이 없었다고 한다.</p>
<br>
3. Historical Averaging과 One-sided Label Smoothing
<p>Historical Averaging은 Training을 여러 번 할 때 기존 Cost들을 Averaging하는 Online-learning 방법이고, One-sided Label Smoothing은 Discriminator Label로서 0과 1대신 좀 더 Smooth한 값을 쓰자는 것인데 사실 웹 어디에도 이것에 대해 자세한 설명이 없고 코드도 없는 걸 보면 사실 별 성능 향상은 없는 듯 싶다.</p>
<br>
4. Inception Score
<p>그나마 새로운 개념은 Inception Score인데, Generative Model의 문제 중 하나인 성능 평가에 대해서 하나의 제시 방법이라고 볼 수 있다. 수식은 다음과 같다.</p>
<p>$$ InceptS = exp(E_{x}KL(p(y|x) || p(y)) = exp(E_{x}E_{p(y|x)}[log(\frac{p(y|x)}{p(y)})]$$</p>
<p>논문에서는 Human Judgement와의 Correlation이 높았다.. 라고만 주장하고 어떠한 실험도 없이 그냥 넘어가는데, 수식을 그대로 해석하면 &ldquo;잘&rdquo; Generated된 Image는 다음과 같을 것이다.</p>
<ul>
<li>Inception Model로 Training된 Label Prediction에서 p(y|x)의 Entropy가 낮을 것이다</li>
<li>Data가 다양하게 Generation되어 p(y)의 Entropy가 높을 것이다</li>
</ul>
<br>
즉, 좋은 Generator일 수록 분자가 높고 분모가 낮을 테니 높은 값이라는 주장이다.
<br>
5. Semi-supervised Learning
<p>Semi-supervised는 하나의 분야로서, 결국은 Supervised Learning (ex. Classification)을 위한 것이다. 좋은 GAN으로 생성된 Image는 적은 Label의 영향을 받아서 일종의 Data Augmentation이 되고, 최종적으로 Classification Accuracy가 높다는 것이다. 이것은 새로운 Supervised-Loss를 정의함으로서 구현 가능하다.</p>
<p>일단은 Semi-supervised도 나름대로의 분야이기에 지금은 Generative Model을 좀 더 공부해야 하므로 나중에 기회가 되면 보기로 하고 마무리..</p>
<p><br><br></p>
<h3 id="3-info-gan">3. Info-GAN</h3>
<br>
<h4 id="3-1-info-gan-description">3-1. Info-GAN Description</h4>
<br>
<p>원 논문의 Chap. 4부터 시작되는 내용이 핵심인데, Original GAN은 <code>z</code>로부터 Generation을 하지만 결국 <code>z</code>가 Data의 Semantic Feature라고 보기는 어렵다는 것이다. 즉 기존에는, DCGAN처럼 <code>z</code>에서 의미를 추출해내기 위해서는 <code>z</code>를 찾기 위해 주먹구구식으로 찾는 방법을 사용했었는데, 그렇게 하지 말고 Latent Vector가 의미를 갖도록 만들자는 것이 Info-GAN의 핵심이다.</p>
<p>즉 핵심 아이디어는 2가지가 되는데.</p>
<ul>
<li>
<ol>
<li>Latent Vector <code>z</code>는 Data를 Generation하는 아주 기본적인 요소들 (Meaningless한)을 담당한다.</li>
</ol>
</li>
<li>
<ol start="2">
<li>Latent Code <code>c</code>는 Data의 의미론적인 Feature로서 역할을 할 수 있게 학습하며, 이 <code>c</code>와 이로부터 Generation된 Data간의 <code>상호 정보량</code>이 최대가 되도록 학습한다.</li>
</ol>
</li>
</ul>
<br>
즉, 딱 보았을 때는 새로운 Generator의 Input `c`가 추가되는 것에 불과하다. 하지만 이대로 학습하면 결국 다른 점이 없다!
<p>결국 최종 Objective Function은 Original GAN으로 부터 다음과 같이 변하게 되는데,</p>
<p>$$ \min_ {G}{\max_ {D}{V_I(D, G)}} = V(D, G) - \lambda I(c;G(z,c)) $$</p>
<p>여기서 <code>V(D, G)</code>는 기존 GAN의 Min-Max Objective Function인데. 여기에 <code>I</code> 부분이 추가되는 것이다. 단 <code>I</code>는 Generator의 제약식이므로, 전체 식이 Minimize되어야 좋은 것이므로 <code>I</code>는 최대가 되어야 좋다는 것을 직관적으로 알 수 있다. 그렇다면 남은 것은 <code>I</code>가 무엇이냐 하는 것이다.</p>
<p><code>I</code>는 앞서 말한 핵심 아이디어의 2. 번에 해당하는 Latent Code <code>c</code>와 이로부터 생성된 Generator Output 사이의 상호 정보량(Mutual Information)이라는 것이다.</p>
<p>우선 복습을 좀 해 보면, 우선 엔트로피는 다음과 같이 정의되며,</p>
<p>$$ H(X) = -\sum_ {}^{}{p(x)log(p(x))} $$</p>
<p>쉽게 해석하면 불확실성, 불확정성이라고 해석할 수 있다. 그렇다면 다음은?</p>
<p>$$ H(X|Y) = E_{y, x}[-log(p(x|y))] $$</p>
<p>Conditional Entropy로서, Y가 주어졌을 경우의 X의 엔트로피, 불확실성, 불확정성이 된다. 수식이 저렇게 정리되는 것은 엔트로피와 조건부 확률의 정의에 의해서이다.</p>
<p>그렇다면 상호 정보량은 수식으로 다음과 같이 나타내는데,</p>
<p>$$ I(X;Y) = H(X) - H(X|Y) $$</p>
<p>이 말을 글자 그대로 해석하면, 상호 정보량이란, X만 알 때의 불확실성이, Y를 알게 됨으로서 사라지는 정도라고 볼 수 있다. 예를 들어 Y와 X가 서로 관계가 없다면. <code>H(X|Y)</code>는 <code>H(X)</code>와 별 차이가 없게 되어 상호 정보량은 감소한다. 반대로 Y와 X가 서로 관계가 높을수록 <code>H(X|Y)</code>, 즉 Y를 알 때의 X의 불확실성이 크게 감소하여 상호 정보량이 커지게 된다. 따라서 우리의 Objective Function 속에 들어 있는</p>
<p>$$ I(c;G(z,c)) $$</p>
<p>을 통해서, Latent Code가 들어갔을 경우 생성되는 Generated Data가 서로 상호 정보량이 많도록, 즉 긴밀한 관계를 유지하도록 전체 GAN이 학습되기를 원하는 것이다.</p>
<p>그렇다면, 우리가 Maximize하고자 하는 이 상호 정보량은 어떻게 계산할까? 수식 전개를 보면,</p>
<p>$$ I(c;G(z,c)) = H({c}) - H(c|G(z,c)) $$
$$ = H({c}) - (-E_{x \sim G(z,c)}[E_{c&rsquo; \sim P(c|x)}[log(P(c'|x))]]) $$</p>
<p>여기서 <code>P(c|x)</code>를 알 수 없기에, 이를 근사하는 Q Network를 만들었다고 가정해 보면 수식은 다음과 같이 단순화된다.</p>
<p>$$ H({c}) + E_{x \sim G(z,c)}[E_{c&rsquo; \sim P(c|x)}[log(Q(c'|x)) + D_{KL}(P|Q)]] $$</p>
<p>이것은 P = Q(P의 근사) + P와 Q의 차이(KL-Divergence)이기에 가능하다. 다만 KL-Divergence Term은 항상 양수이므로 무시할 수 있게 되어 결국 다음을 최대화하면 된다.</p>
<p>$$ H({c}) + E_{x \sim G(z,c)}[E_{c&rsquo; \sim P(c|x)}[log(Q(c'|x))]] $$</p>
<p>문제는 기댓값을 구할 때 Sampling하는 과정에서도 <code>P(c|x)</code>가 존재하기에 한번 더 수학적 Trick을 사용하는데, 논문에 나오는 Lemma 5.1을 이용하는 것이다. (더 공부 필요)</p>
<p>$$ E_{x \sim G(z,c), c \sim P({c})}[log(Q(c|x))] + H({c}) $$</p>
<p>결국 이 식은 Maximum Likelihood 식이 된다. 어떤 경우에? 확률분포 <code>P(c)</code>로부터 <code>c</code>를 얻어서 Generator를 통과시켜서 나온 <code>x</code>가 있을 경우에 이것이 Q Network를 통과했을 경우 <code>c</code>의 Maximum Likelihood라는 것이다. 이것을 최대화 한다는 것은 결국 다음 문장으로 요약 가능하다.</p>
<p>&ldquo;Latent Code c의 복원 오차를 최소화 하자&rdquo;</p>
<p>코드를 짜는 입장에서는 Loss Function을 Minimize하는 것이 더 좋으므로 저 복원 오차를 Loss로 잡아서 Objective Function에 더해 주면 된다.</p>
<p>$$ D_{Loss} = D_{GANLoss} + \lambda C_{Loss} $$
$$ G_{Loss} = G_{GANLoss} + \lambda C_{Loss} $$</p>
<p>여기서 중요한 것은 Latent Code인 <code>c</code>를 넣어주는 방식인데, 우리는 Semantic Feature가 Label값과 같은 Class로 구분되기를 원할 수도 있고 (ex. MNIST), 연속적인 값 (얼굴의 회전 정도, 표정 등)을 갖기를 원할수도 있다. 이에 대해 가이드라인이 존재하는데, Cateogrical Code의 경우에는 마치 One-hot Encoding을 하듯이 넣어 주고, (즉, Dimension이 Class의 수가 된다) Cross Entropy-like한 방법으로 복원 오차를 구하면 된다. Continuous Code는 Uniform Distribution이나 Gaussian Distribution으로 넣어 주고 복원된 <code>c</code>를 가지고 몬테-카를로 방법으로 추정한 확률분포 사이의 Continuous Error Measurement를 하면 된다.</p>
<p>요약하여, GAN과 비교하여 전체 System의 구조를 보면 다음과 같게 된다.</p>
<center> <img src="/img/InfoGANStructure.PNG" style="width:600px" /></center>
<p>어떻게 Latent Code를 이용해서 의미 있는 Output을 쉽게 Generation을 하는 지는 실제 구현 단계인 다음 절에서 살펴보도록 하자.</p>
<br>
<h4 id="3-2-info-gan-implemenation">3-2. Info-GAN Implemenation</h4>
<br>
<p>코드는 Pytorch로 구현하였으며, Database는 CelebA, DCGAN 코드를 수정해서 만들었는데, DCGAN Baseline Code는 Yunjey님의 Github Repo.에서 참조하였다.</p>
<p>코드 링크: <a href="https://github.com/taeoh-kim/Pytorch_InfoGAN">Pytorch Github Repository</a></p>
<p>기본적으로 GAN (또는 DCGAN)의 구조를 가지고 있고, Discrete(Categorical) Code와 Continuous Code를 랜덤하게 만들어서 Generator에 Input으로 넣어 줘야 한다. 아래 코드에서 볼 수 있듯이 <code>z</code>에 붙여서 넣으면 된다. 학습이 완료 되면 나중에 원하는 Feature를 가진 Image를 Generation할 때 그 분포와 Categorical Class를 따라가게 된다.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">input_to_G <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>cat((noise, continuous_code_input, discrete_code_input), <span style="color:#ae81ff">1</span>)
fake <span style="color:#f92672">=</span> G(input_to_G)

input_to_D <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>cat([images, fake])

outputs <span style="color:#f92672">=</span> D(input_to_D)
</code></pre></div><br>
<p>위 코드에서 결과로 나오는 outputs에는 기존 Real이냐 Fake냐를 나타내는 1x1 Size의 Label값과 더불어 Code도 나오게 된다. 따라서 Code의 Loss를 측정해서 Discriminator Loss에 더해 주고 학습시키면 된다.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">D<span style="color:#f92672">.</span>zero_grad()

continuous_code_output <span style="color:#f92672">=</span> outputs[batch_size:, <span style="color:#ae81ff">1</span>:<span style="color:#ae81ff">1</span><span style="color:#f92672">+</span>num_of_continuous_code]
discrete_code_output <span style="color:#f92672">=</span> outputs[batch_size:, <span style="color:#ae81ff">1</span><span style="color:#f92672">+</span>num_of_continuous_code:<span style="color:#ae81ff">1</span><span style="color:#f92672">+</span>num_of_continuous_code<span style="color:#f92672">+</span>num_of_class_of_category]

Loss_continuous <span style="color:#f92672">=</span> MSE(continuous_code_output, Distribution_of_continuous_code_generator)
Loss_discrete <span style="color:#f92672">=</span> CrossEntropy(discrete_code_output, discrete_code_input)

Loss_D <span style="color:#f92672">=</span> BCE(outputs[:,<span style="color:#ae81ff">0</span>], real_and_fake_labels) <span style="color:#f92672">+</span> Lambda1 <span style="color:#f92672">*</span> Loss_continuous <span style="color:#f92672">+</span> Lambda2 <span style="color:#f92672">*</span> Loss_discrete

Loss_D<span style="color:#f92672">.</span>backward(retain_variables<span style="color:#f92672">=</span>True)
D_optimizer<span style="color:#f92672">.</span>step()
</code></pre></div><br>
<p>이어서 Generator를 학습하는 코드인데, Fake Image만 학습한다는 것 빼고는 Discriminator와 동일하다.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">G<span style="color:#f92672">.</span>zero_grad()

Loss_G <span style="color:#f92672">=</span> BCE(outputs[batch_size:,<span style="color:#ae81ff">0</span>], real_labels) <span style="color:#f92672">+</span> Lambda1 <span style="color:#f92672">*</span> Loss_continuous <span style="color:#f92672">+</span> Lambda2 <span style="color:#f92672">*</span> Loss_discrete

Loss_G<span style="color:#f92672">.</span>backward()
G_optimizer<span style="color:#f92672">.</span>step()
</code></pre></div><br>
<p>학습이 끝나면 우리가 원하는 Feature를 가진 Image를 만드는 방법은 확실하게 보기 위해서 <code>z</code>를 고정하고. Continuous Code의 경우에는 linspace를 이용해서 점차적으로 변화되도록 <code>c</code>를 Generator에 Input으로 넣어 주면 되고. Categorical의 경우에는 One-hot Vector의 형식으로 넣어주면 된다. 아래 코드를 참조하자.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">fix_cont_codes <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>zeros((<span style="color:#ae81ff">100</span>,<span style="color:#ae81ff">2</span>))
fix_cont_codes[<span style="color:#ae81ff">0</span>:<span style="color:#ae81ff">25</span>,<span style="color:#ae81ff">0</span>] <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>linspace(<span style="color:#f92672">-</span><span style="color:#ae81ff">3</span>,<span style="color:#ae81ff">3</span>,<span style="color:#ae81ff">25</span>)
fix_cont_codes[<span style="color:#ae81ff">50</span>:<span style="color:#ae81ff">75</span>,<span style="color:#ae81ff">0</span>] <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>linspace(<span style="color:#f92672">-</span><span style="color:#ae81ff">3</span>,<span style="color:#ae81ff">3</span>,<span style="color:#ae81ff">25</span>)
fix_cont_codes[<span style="color:#ae81ff">25</span>:<span style="color:#ae81ff">50</span>,<span style="color:#ae81ff">1</span>] <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>linspace(<span style="color:#f92672">-</span><span style="color:#ae81ff">3</span>,<span style="color:#ae81ff">3</span>,<span style="color:#ae81ff">25</span>)
fix_cont_codes[<span style="color:#ae81ff">75</span>:<span style="color:#ae81ff">100</span>,<span style="color:#ae81ff">1</span>] <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>linspace(<span style="color:#f92672">-</span><span style="color:#ae81ff">3</span>,<span style="color:#ae81ff">3</span>,<span style="color:#ae81ff">25</span>)
fix_cont_codes <span style="color:#f92672">=</span> Variable(fix_cont_codes)

fix_disc_codes <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>zeros((<span style="color:#ae81ff">100</span>,<span style="color:#ae81ff">2</span>))
fix_disc_codes[<span style="color:#ae81ff">0</span>:<span style="color:#ae81ff">50</span>,<span style="color:#ae81ff">0</span>] <span style="color:#f92672">=</span> <span style="color:#ae81ff">1</span>
fix_disc_codes[<span style="color:#ae81ff">50</span>:<span style="color:#ae81ff">100</span>,<span style="color:#ae81ff">1</span>] <span style="color:#f92672">=</span> <span style="color:#ae81ff">1</span>
fix_disc_codes <span style="color:#f92672">=</span> Variable(fix_disc_codes)

fix_noise <span style="color:#f92672">=</span> Variable(torch<span style="color:#f92672">.</span>Tensor(np<span style="color:#f92672">.</span>zeros((<span style="color:#ae81ff">100</span>, z_dim))))

inputs <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>cat((fix_noise, fix_cont_codes, fix_disc_codes), <span style="color:#ae81ff">1</span>)
generated_images <span style="color:#f92672">=</span> G(inputs)

torchvision<span style="color:#f92672">.</span>utils<span style="color:#f92672">.</span>save_image(Denormalization(generated_image<span style="color:#f92672">.</span>data), Output File Name, nrow<span style="color:#f92672">=</span><span style="color:#ae81ff">10</span>)
</code></pre></div><br>
<br>
<h4 id="3-3-info-gan-results">3-3. Info-GAN Results</h4>
<br>
<p>CelebA 결과를 보면, 중요한 특징은 돌릴 때마다 <code>c</code>가 캐치해 내는 Feature가 조금씩 바뀐다는 것이다. 하지만 순서만 바뀔 뿐, 대충 사람이 인지하기에도 중요한 Feature들이 학습되는 것을 확인할 수가 있다.</p>
<p>첫 번째 수행결과의 경우에는, 위/아래 Set는 2개의 Categorical Code로 나뉘어진 것인데, 바라보는 방향에 따라 나누어진 것을 볼 수 있다.</p>
<p>각 Category Set에서는 노란색 선을 기준으로 2개의 Continuous Code가 점차적으로 변화했을 경우를 보여주는데, 하나는 대충 피부색인 듯 하고, 하나는 표정 변화를 보여주고 있다.</p>
<p>즉, 바라보는 방향 (Categorical), 피부색과 표정 (Continuous) 모두 중요한 얼굴의 Feature임을 보여주고 있다.</p>
<p><img src="/img/InfoGANRes1.PNG#floatcenter" alt="figInfoR1"></p>
<p>그리고 생각보다 생성 영상의 Quality가 훌륭하다.</p>
<p>다음은 두번째 수행한 경우인데, 이번엔 미묘하지만 표정으로 Category가 나눠지고, 첫 번째 Continuous Code는 주름의 변화 비슷하게, 두 번째 Continuous Code는 머리와 피부색으로 변화되는 것을 볼 수 있다.</p>
<p><img src="/img/InfoGANRes2.PNG#floatcenter" alt="figInfoR2"></p>
<p><br><br></p>
<h3 id="4-ebgan">4. EBGAN</h3>
<br>
<h4 id="4-1-ebgan-description">4-1. EBGAN Description</h4>
<br>
<p>EBGAN은 LeCun교수 팀에서 낸 논문으로, Energy-based라는 거창한 Title을 달고 있다. 근데 사실 Energy라는게 어려운 것이 아니고 틀리면 높은 에너지, 맞으면 낮은 에너지를 부여하는 전통적인 방법이다. 결국 논문의 Contribution은 Discriminator가 진짜와 가짜를 구분해 내기 보다는 Energy Function으로서 행동하기를 원한다는 것이다. 그렇게 하기 위해서 Discriminator를 Auto-encoder로 만들었고, 나름 결과가 좋았다 라는게 논문의 핵심 내용이다.</p>
<p>논문에서는 다음과 같이 새로운 Loss Function을 제안하는데,</p>
<p>$$ L_D(x, z) = D(x) + [m - D(G(z))]^{+} $$
$$ L_G(z) = D(G(z)) $$</p>
<p>논문에서는 이렇게 Loss Function을 잡으면 System의 Nash Equilibrium이 존재하며, 그 때의 Value Function의 값과 그것을 만족하는 Energy 값이 존재함을 수식적으로 증명한 것 같다. 확실하게 이해했는지는 모르겠지만. 해당 방법으로 Training했을 경우 완벽하게 Nash Equilibrium으로 &ldquo;안정적으로&rdquo; 수렴한다고 볼 수는 없는 것 같다.</p>
<p>우선 위 두2개의 Loss Function에 대한 Value Function을 다음과 같이 정의한다.</p>
<p>$$ V(G, D) = \int _{x, z}^{}{L_D(x, z) p_{data}(x) p_z(z) dx dz} $$
$$ U(G, D) = \int _{z}^{}{L_G(z) p_z(z) dz} $$</p>
<p>결국 Loss의 Minimum을 원하므로, Nash Equilibrium은 다음을 만족한다고 할 수 있다. <code>*</code>이 붙으면 Optimum임을 의미한다.</p>
<p>$$ V(G^{*},D^{*}) \le V(G^{*}, D) \enspace \enspace \forall D $$
$$ U(G^{*},D^{*}) \le U(G, D^{*}) \enspace \enspace \forall G $$</p>
<p>논문에서는 다음 두 가지를 증명하고 있다</p>
<ul>
<li>1번. D*, G*가 Nash Equilibrium이라면, Generator의 Data 확률 분포와 원본 Data 확률분포가 일치하며 (<code>p_g = p_data</code>), 그 때의 V(D*, G*) = m 이다.</li>
<li>2번. Nash Equilibrium이 존재하며, 그 때 D*(x)=C를 만족하는 상수 C가 존재한다.</li>
</ul>
<br>
우선 1.에 대한 증명을 먼저 살펴 보면, 우선 Discriminator의 Loss Function을 그대로 Value Function에 대입 한 것인데, G를 Optimum으로 가정해서 그런지 수식 전개가 (분배법칙) 깔끔한 느낌은 아니었다. (이해 안되는 부분 1)
<p>$$ V(G^{*},D) = \int _{x}^{}{p_{data}(x)D(x)dx} + \int _{z}^{}{p_z(z) [m-D(G^{*}(z))]^{+} dz} $$</p>
<p>일단 맞다고 가정하고. G가 Optimum이므로 z domain이 합쳐지면 다음 수식으로 정리된다.</p>
<p>$$ V(G^{*},D) = \int _{x}^{}{p_{data}(x)D(x) + p_{G^{*}}(x) [m-D(x)]^{+}  dx}  \enspace \enspace &hellip; (6) $$</p>
<p>적분식 안에 있는 수식을 단순화하면 다음으로 치환할 수 있는데,</p>
<p>$$ \varphi (x) = ax + b(m-x)^{+} \enspace \enspace where \enspace \enspace a=p_{data}, \enspace b=p_{G^{*}}, \enspace x=D(x)$$</p>
<p>저 함수를 1차함수라고 생각하면 누구나 쉽게 대략적인 모습을 그려볼 수 있다.</p>
<p>결론적으로는 다음처럼 되는데,</p>
<ul>
<li>a &lt; b 라면, 최소값이 되는 D(x) = m, 그때의 최소값은 am</li>
<li>a &gt; b 라면, 최소값이 되는 D(x)는 m보다 작고, 그 때의 최소값은 bm (D(x)=0일 경우)</li>
</ul>
<br>
즉,
<p>$$ D^{*}(x) \le m $$</p>
<p>이다. 이 조건도 뒤에 나오므로 기억해 두자.</p>
<p>이 말을 그대로 수식으로 풀면 다음 전개로 넘어갈 수가 있다.</p>
<p>$$ V(G^{*},D^{*}) = m \int _{x}^{}{ 1_{ p_{data}(x) &lt; p_{G^{*}}} \cdot p_{data}(x) dx} + m \int _{x}^{}{ 1_{ p_{data}(x) \ge p_{G^{*}} } \cdot p_{G^{*}}(x) dx} $$</p>
<p>여기서 1은 아래 조건이 만족되면 1, 아니면 0을 의미한다.</p>
<p>간단하게 정리를 하면 최종적으로 다음 수식이 된다.</p>
<p>$$ V(G^{*},D^{*}) = m + m \int _{x}^{}{ 1_{ p_{data}(x) &lt; p_{G^{*}}} \cdot (p_{data}(x) - p_{G^{*}}(x)) dx} \enspace \enspace &hellip; (10)$$</p>
<p>여기서 2번째 항을 잘 보면, a &lt; b일때 (p_data &lt; p_G) 만 값을 가지는데, 그러면 (p_data - p_G)가 음수가 된다. 즉 0보다 같거나 작다, 즉 최종적으로</p>
<p>$$ V(G^{*},D^{*}) \le m $$</p>
<p>이라는 것이 된다.</p>
<p>이어서, (이해가 안되는 부분 2) 다음 수식(위에 있는 Value Function)으로 부터,</p>
<p>$$ U(G^{*},D^{*}) \le U(G, D^{*}) $$</p>
<p>왜 이걸 대입하는지 이해가 잘 안 되지만, 완벽한 Generator라면 Real Data 분포일때 보다 Generator 부분의 Loss가 작아야 한다는 것이 아닐까? 라고 스스로 해석하고 넘어가 본다.. 즉, 위 식의 우변에 <code>p_data</code>를 대입하는 것인데, 사실 이부분도 결국 깔끔하게 이해가 되지는 않았다.</p>
<p>$$ \int _{x}^{}{ p_{G^{*}}(x) D^{*}(x) dx} \le \int _{x}^{}{ p_{data}(x) D^{*}(x) dx} \enspace \enspace &hellip; (11) $$</p>
<p>아무튼 이 수식을 기억한 채로, (6)수식을 다시 가져온 뒤 D를 D*를 치환하면,</p>
<p>$$ V(G^{*},D^{*}) = \int _{x}^{}{p_{data}(x)D^{*}(x) + p_{G^{*}}(x) [m-D^{*}(x)]^{+}  dx} $$</p>
<p>여기서 p_data(x)를 p_G*(x)로 바꾸면 식 (11)에 의하여,</p>
<p>$$ \int _{x}^{}{p_{G^{*}}(x)D^{*}(x) + p_{G^{*}}(x) [m-D^{*}(x)]^{+}  dx}  \le V(G^{*},D^{*}) $$</p>
<p>위 식의 좌변은</p>
<p>$$ D^{*}(x) \le m $$</p>
<p>이라면,</p>
<p>$$ \int _{x}^{}{p_{G^{*}}(x) \cdot m dx} $$
$$ = m \cdot \int _{x}^{}{p_{G^{*}}(x) dx} $$
$$ = m $$</p>
<p>이 된다. (확률의 총 합은 1이므로) 즉, 다음과 같이 결론지을 수 있다.</p>
<p>$$ m \le V(G^{*},D^{*}) \le m $$
$$ V(G^{*},D^{*}) = m $$</p>
<p>여기에서 식 (10)에 의해 이 경우가 되려면 우변의 두번째 항 = 0이어야 하므로,</p>
<p>$$ p_{data}(x) = p_{G^{*}}(x) $$</p>
<p>여야만 하기에, 1번에 대한 증명이 마무리가 된다. (수학적으로 Almost Everywhere인 부분은 편의상 생략..)</p>
<p>하지만 2번 증명은 (증명이 길지도 않은데 Appendix로 왜 넘겼을까..) 뭔가 Tricky하게 넘어가는데 우선은 자세한 증명은 생략하도록 하지만. 글로서 풀어보자면. 일단 Nash Equilibrium 존재하고, 그때의 확률분포도 정해져 있다는 것이 증명되었고 (1번 증명을 포함하여) D*(x) &lt; m 이고.. 결국 추가된 건 다음 하나뿐인데,</p>
<p>$$ D^{*}(x) = C $$</p>
<p>이러한 Constant값이 Almost Everywhere에서 반드시 존재한다는 것이다. (이 말이 Discriminator가 Equilibrium에 도달했다는 것을 의미하는 것 같다.)</p>
<p>Appendix에서는 이것이 Constant가 아닐 경우의 모순을 보여주면서 증명이 끝이 난다.. 그래서 결국 내 생각 (혹은 이해 부족)이지만 논문 어디에도 이 System 혹은 Network의 구조가 반드시 수렴한다는 (Equilibrium에 도달한다는) 이야기는 없다. 논문 제목과 내용이 겉도는 느낌이 드는 이유가 여기에 있는 것 같다. 후속 GAN 논문을 계속 읽어보면서 내가 이해를 못 한 건지 뭔지에 대해 좀 더 살펴봐야 할 것 같다.</p>
<p>하지만 Practical하게 사용하는 엔지니어의 입장으로서는.. 그냥 넘어가는게 정신건강에 좋은 것 같은 생각도 들긴 한다. 아무튼 실제 Network은 다음 절을 참고하자.</p>
<br>
<h4 id="4-2-ebgan-model-with-auto-encoder-and-implementation">4-2. EBGAN Model with Auto-Encoder and Implementation</h4>
<br>
<p>결국! Energy Function은 Discriminator의 Auto-Encoder의 Reconstruction Error로 쓰겠다는 것이 실제 구현시의 핵심이다. EBGAN 구조는 아래처럼 된다.</p>
<center> <img src="/img/EBGANStructure.PNG" style="width:600px" /></center>
<br>
<p>사실 왜 Auto Encoder를 썼는지에 대한 설명은 Energy Function 이상의 것은 아닌 것 같다. 직관적으로 보기에도 단순히 Real, Fake를 구분하는 것 보다는 나아 보인다. Auto Encoder가 Real Image를 넣었을 경우 제대로 다시 복원해 낼 줄 안다면, Fake Image가 들어갔을 경우에도 그렇게 학습되도록 해서 Generator가 더 실제적인 Image를 만들어 내게 하는 것이다. 좀 더 유연해지는 느낌이다.</p>
<p>그리고 논문에서는 Generator Loss에 Regularizer를 추가한다. 일종의 Minibatch Discrimination과 같은 맥락이라 볼 수 있는데 Batch Set의 Feature Output을 추가하는 것이다. 수식으로는 다음과 같다.</p>
<p>$$ L_G(z) = D(G(z)) + \lambda \cdot f_{PT} $$</p>
<p>$$ f_{PT}(S) = \frac{1}{N(N-1)} \sum _{i=1}^{N}{\sum _{j=1, j \neq i}^{N}{(\frac{S^T_i \cdot S_j}{\left | S_i \right | \cdot \left | S_j \right |})^2}} $$</p>
<p>마찬가지로 DCGAN 기반의 코드 구현으로, 링크는 다음과 같다.</p>
<p>코드 링크: <a href="https://github.com/taeoh-kim/GAN_pytorch/">Pytorch Github Repository</a></p>
<p>하나씩 보면, 논문에서 제안한 Loss를 기반으로 Discriminator를 학습하는 코드이다. Loss가 MSE인 것이 Point이다.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">fake <span style="color:#f92672">=</span> G(noise)
fake_recon <span style="color:#f92672">=</span> D(fake)
real_recon <span style="color:#f92672">=</span> D(images)

fake_loss <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>mean(torch<span style="color:#f92672">.</span>sum((fake_recon <span style="color:#f92672">-</span> fake) <span style="color:#f92672">**</span> <span style="color:#ae81ff">2</span>, <span style="color:#ae81ff">1</span>))
real_loss <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>mean(torch<span style="color:#f92672">.</span>sum((real_recon <span style="color:#f92672">-</span> images) <span style="color:#f92672">**</span> <span style="color:#ae81ff">2</span>, <span style="color:#ae81ff">1</span>))

D_loss <span style="color:#f92672">=</span> real_loss <span style="color:#f92672">+</span> F<span style="color:#f92672">.</span>relu(Margin <span style="color:#f92672">-</span> fake_loss)

D<span style="color:#f92672">.</span>zero_grad()
D_loss<span style="color:#f92672">.</span>backward()
D_opt<span style="color:#f92672">.</span>step()
</code></pre></div><br>
<p>다음은 Generator를 학습하는 코드이다.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">fake <span style="color:#f92672">=</span> G(noise)
fake_recon <span style="color:#f92672">=</span> D(fake)

G_loss <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>mean(torch<span style="color:#f92672">.</span>sum((fake_recon <span style="color:#f92672">-</span> fake) <span style="color:#f92672">**</span> <span style="color:#ae81ff">2</span>, <span style="color:#ae81ff">1</span>))
</code></pre></div><br>
<p>Regularizer를 추가하려면 위 수식을 구현해야 하는데, 위 수식은 다음과 같이 해석된다.</p>
<ul>
<li>Sample 단위로 곱한다</li>
<li>그것을 각 Sample의 Norm의 곱으로 나눈다</li>
<li>제곱해서 다 더한뒤 N(N-1)로 나눈다</li>
</ul>
<p>이것을 For문 없이 Matrix로 다음 그림처럼 만들 수 있다. (분자 부분)</p>
<center> <img src="/img/PTReg1.PNG" style="width:600px" /></center>
<p>그러면 결국 모든 Cross Sample간의 곱으로 Matrix가 생기는데, 같은 Sample끼리는 제외되어야 하므로 대각 성분을 제거해 준다.</p>
<center> <img src="/img/PTReg2.PNG" style="width:600px" /></center>
<p>분모 부분(Norm)은 각 Sample별로 구한 뒤 분자와 Size를 맞춰주기 위해서 (feature_dimension x batch_size)형태의 Matrix로 만들어 준다.</p>
<center> <img src="/img/PTReg3.PNG" style="width:600px" /></center>
<p>그러면 아래처럼 곱하면 각 Element가 Norm의 Cross곱을 가지게 되며, 이것을 분자에서 나누고 제곱하면 된다.</p>
<center> <img src="/img/PTReg4.PNG" style="width:600px" /></center>
<center> <img src="/img/PTReg5.PNG" style="width:600px" /></center>
<p>모든 Element를 더해서 N(N-1)로 나눠준 스칼라 값을 Generator Loss에 더하면 된다.</p>
<p>코드는 아래와 같다.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">M <span style="color:#f92672">=</span> fake<span style="color:#f92672">.</span>view(<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>, batch_size) <span style="color:#75715e"># Data_Dimension x Batch_Size</span>

nom <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>mm(torch<span style="color:#f92672">.</span>transpose(M,<span style="color:#ae81ff">0</span>,<span style="color:#ae81ff">1</span>), M) <span style="color:#75715e"># Batch_Size x Batch_Size</span>

tmp <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>zeros((data_dimension, batch_size))
tmp_column <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>sqrt(torch<span style="color:#f92672">.</span>sum((M)<span style="color:#f92672">**</span><span style="color:#ae81ff">2</span>), <span style="color:#ae81ff">0</span>))
tmp[<span style="color:#ae81ff">0</span>,:] <span style="color:#f92672">=</span> tmp_column<span style="color:#f92672">.</span>data

denom <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>mm(torch<span style="color:#f92672">.</span>transpose(tmp,<span style="color:#ae81ff">0</span>,<span style="color:#ae81ff">1</span>), tmp)

pt <span style="color:#f92672">=</span> ( nom<span style="color:#f92672">.</span>data <span style="color:#f92672">/</span> denom<span style="color:#f92672">.</span>cuda() ) <span style="color:#f92672">**</span> <span style="color:#ae81ff">2</span>

<span style="color:#75715e"># Remove Diagonal Elements</span>
pt <span style="color:#f92672">-=</span> torch<span style="color:#f92672">.</span>diag(torch<span style="color:#f92672">.</span>diag(pt, <span style="color:#ae81ff">0</span>))
pt <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>sum(pt) <span style="color:#f92672">/</span> (batch_size <span style="color:#f92672">*</span> (batch_size <span style="color:#f92672">-</span> <span style="color:#ae81ff">1</span>))

G_loss <span style="color:#f92672">+=</span> pt_lambda <span style="color:#f92672">*</span> pt
</code></pre></div><br>
<p>Training/Test과정은 일반적인 GAN과 동일하다.</p>
<br>
<h4 id="4-3-ebgan-results">4-3. EBGAN Results</h4>
<br>
<p>CelebA 결과를 보자. PT는 Regularizer이며, m은 Margin을 의미한다. 사실 결과만 두고 봤을 경우 DCGAN과 크게 뭐가 다른가 싶다. 아직은 EBGAN의 진가를 확인하려면 좀 더 연구와 공부가 필요해 보인다.</p>
<p><img src="/img/EBGANRes.PNG#floatcenter" alt="figEBR"></p>
<p><br><br></p>
<h3 id="마치며">마치며..</h3>
<p>2016년정도까지 나왔던, DCGAN 이후의 몇 개의 GAN 논문들을 읽고, 분석하고 구현해 보았다. 이어서 언제가 될 지 모르지만 머지 않은 시간 내에 2016년 후반 - 2017년 GAN Trend까지 Rough하게나마 Follow하는 것을 목표로 하고 있다.</p>
<br>

            </div>
        </div>
    </div>
</section>


        </div><!-- Footer Start -->
<footer id="footer" class="bg-one">
    <div class="footer-bottom">
        <h5>Copyright 2020. All rights reserved.</h5>
        <h6>Taeoh Kim
        <br>Design by themefisher.com
        <br>Powered by Hugo
        </h6>
    </div>
</footer>
<!-- end footer -->


<!-- Essential Scripts -->

<!-- jQuery -->
<script src="https://taeoh-kim.github.io/plugins/jquery/dist/jquery.min.js"></script>
<!-- Bootstrap -->
<script src="https://taeoh-kim.github.io/plugins/bootstrap/dist/js/popper.min.js"></script>
<script src="https://taeoh-kim.github.io/plugins/bootstrap/dist/js/bootstrap.min.js"></script>
<!-- Parallax -->
<script src="https://taeoh-kim.github.io/plugins/parallax/jquery.parallax-1.1.3.js"></script>
<!-- lightbox -->
<script src="https://taeoh-kim.github.io/plugins/lightbox2/dist/js/lightbox.min.js"></script>
<!-- Slick Carousel -->
<script src="https://taeoh-kim.github.io/plugins/slick-carousel/slick/slick.min.js"></script>
<!-- Portfolio Filtering -->
<script src="https://taeoh-kim.github.io/plugins/filterzr/jquery.filterizr.min.js"></script>
<!-- Smooth Scroll js -->
<script src="https://taeoh-kim.github.io/plugins/smooth-scroll/dist/js/smooth-scroll.min.js"></script>
<script src="https://maps.googleapis.com/maps/api/js?key=AIzaSyCC72vZw-6tGqFyRhhg5CkF2fqfILn2Tsw"></script>
<!-- Main Script -->

<script src="https://taeoh-kim.github.io/js/script.min.js"></script>
</body>
</html>
