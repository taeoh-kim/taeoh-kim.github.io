
<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Taeoh Kim</title>

  <meta name="author" content="Taeoh Kim">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <link rel="stylesheet" type="text/css" href="style.css">
  <link rel="icon" type="image/png" href="images/seal_icon.png">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Taeoh Kim</name>
              </p>
              <p>Research Engineer / Technical Lead. at, <a href="https://www.navercloudcorp.com/">NAVER Cloud Corp.</a>
              </p>
              <p>
                My research interests are <strong>1) Video Understanding</strong> including Multimodal Video Understanding such as Video-LLMs, Video Captioning, Video Question Answering, Video Retrieval, Moment Retrieval, ...,
              and <strong>2) Video-based Computer Vision</strong> including Action Recognition, Temporal Action Detection, Video Object Detection/Tracking/Segmentation, Person Re-Identification, ...,
              and other topics such as Video Generation, 3D Representations (e.g. NeRF, Gaussian Splatting), Human Pose Estimation, and 3D Human Reconstruction (e.g. SMPL-X).
              </p>
              <p>We are looking for research interns who are interested in the above related areas. Please feel free to reach out to me.</a>
              </p>
              <p>
                E-mail: taeoh.kim [at] navercorp.com
              </p>
              <p style="text-align:center">
                <a href="https://scholar.google.com/citations?user=mMgadisAAAAJ&hl=ko">Google Scholar</a> &nbsp/&nbsp
                <a href="https://www.linkedin.com/in/taeoh-kim-547683146">Linkedin</a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="taeoh.jpeg"><img style="width:100%;max-width:100%" alt="profile photo" src="taeoh.jpeg" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

        <h3>News!</h3>
        <p>
          [Jul 2024] One Paper is accepted to <strong>ECCV 2024 <span style="color:#4555EE">(Oral)</span></strong> (Video Action Detection). <br>
          [Jan 2024] I won the <strong>N Innovation Award 2023, R&D Track</strong> <a href="https://d2.naver.com/news/9489625">[About]</a> <a href="https://d2.naver.com/helloworld/7136716">[Post]</a>. <br>
          [Aug 2023] One Paper is accepted to <strong>International Journal of Computer Vision</strong> (Image Processing). <br>
          [Feb 2023] One Paper is accepted to <strong>CVPR 2023</strong> (Video Action Localization). <br>
          [Jan 2023] One Paper is accepted to <strong>ICLR 2023 <span style="color:#4555EE">(Spotlight)</span></strong> (Video Understanding). <br>
          [Nov 2022] One Paper is accepted to <strong>AAAI 2023 <span style="color:#4555EE">(Oral)</span></strong> (Video Representation Learning). <br>
          [Apr 2022] One Paper is accepted to <strong>Pattern Recognition</strong> (Video Anomaly Detection). <br>
          [Dec 2021] One Paper is accepted to <strong>IEEE Transactions on Image Processing</strong> (Video Deblurring). <br>
          [Nov 2021] One Paper is accepted to <strong>IEEE Transactions on Image Processing</strong> (Image Compression). <br>
              </p>
        <br>

        <h3>Publications</h3>

        <tr>
          <td style="padding:20px;width:25%;vertical-align:middle">
            <img src="cmatter.png" alt="dcd" width="240" height="100" style="border-style: none">
          </td>
          <td style="padding:20px;width:75%;vertical-align:middle">
              <papertitle>Classification Matters: Improving Video Action Detection with Class-Specific Attention</papertitle>
            <br><br>
            Jinsung Lee, <strong>Taeoh Kim</strong>, Inwoong Lee, Minho Shim, Dongyoon Wee, Minsu Cho, Suha Kwak
            <br><br>
            <em>ECCV</em>, 2024 <strong><span style="color:#4555EE">(Oral Presentation, 2.3% Acceptance Rate)</span></strong>
            <br>
            <a href="https://arxiv.org/pdf/2407.19698">Paper</a> / <a href="https://jinsingsangsung.github.io/ClassificationMatters/">Project Page</a>
            <br>
            <p></p>
          </td>
        </tr>


        <tr>
          <td style="padding:20px;width:25%;vertical-align:middle">
            <img src="ijcv.png" alt="dcd" width="240" height="140" style="border-style: none">
          </td>
          <td style="padding:20px;width:75%;vertical-align:middle">
              <papertitle>A Nonlinear, Regularized, and Data-independent Modulation for Continuously Interactive Image Processing Network</papertitle>
            <br><br>
            Hyeongmin Lee, <strong>Taeoh Kim</strong>, Hanbin Son, Sangwook Baek, Minsu Cheon, Sangyoun Lee
            <br><br>
            <em>Internation Journal of Computer Vision (IJCV, IF 19.5)</em>, 2023
            <br>
            <a href="https://link.springer.com/article/10.1007/s11263-023-01874-y">Paper</a>
            <p></p>
          </td>
        </tr>



        <tr>
          <td style="padding:20px;width:25%;vertical-align:middle">
            <img src="dcd.png" alt="dcd" width="240" height="140" style="border-style: none">
          </td>
          <td style="padding:20px;width:75%;vertical-align:middle">
              <papertitle>Decomposed Cross-modal Distillation for RGB-based Temporal Action Detection</papertitle>
            <br><br>
            Pilhyeon Lee, <strong>Taeoh Kim</strong>, Minho Shim, Dongyoon Wee, Hyeran Byun
            <br><br>
            <em>CVPR</em>, 2023
            <br>
            <a href="https://arxiv.org/abs/2303.17285">Paper</a>
            <p></p>
          </td>
        </tr>



        <tr>
          <td style="padding:20px;width:25%;vertical-align:middle">
            <img src="dynaaug.png" alt="dynaaug" width="240" height="110" style="border-style: none">
          </td>
          <td style="padding:20px;width:75%;vertical-align:middle">
              <papertitle>Exploring Temporally Dynamic Data Augmentation for Video Recognition</papertitle>
            <br><br>
            <strong>Taeoh Kim</strong>, Jinhyung Kim, Minho Shim, Sangdoo Yun, Myunggu Kang, Dongyoon Wee,
            Sangyoun Lee
            <br><br>
            <em>ICLR</em>, 2023 <strong><span style="color:#4555EE">(Spotlight Presentation, Notable Top 25%)</span></strong>
            <br>
            <a href="https://arxiv.org/abs/2206.15015">Paper</a> /
            <a href="https://openreview.net/pdf?id=fxjzKOdw9wb">OpenReview</a>
            <p></p>
          </td>
        </tr>



        <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="freqaug.png" alt="freqaug" width="240" height="140" style="border-style: none">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle>Frequency Selective Augmentation for Video Representation Learning</papertitle>
              <br><br>
              Jinhyung Kim,
              <strong>Taeoh Kim</strong>, Minho Shim, Dongyoon Han, Dongyoon Wee,
              Junmo Kim
              <br><br>
              <em>AAAI</em>, 2023 <strong><span style="color:#4555EE">(Oral Presentation)</span></strong>
              <br>
              <a href="https://arxiv.org/abs/2204.03865">Paper</a>
              <p></p>
            </td>
          </tr>






          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="flowano.png" alt="flowano" width="240" height="140" style="border-style: none">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle>Unsupervised Video Anomaly Detection via Normalizing Flows with Implicit Latent Features</papertitle>
              <br><br>
              MyeongAh Cho,
              <strong>Taeoh Kim</strong>, Woo Jin Kim, Suhwan Cho,
              Sangyoun Lee
              <br><br>
              <em>Pattern Recognition (PR, IF 8.0)</em>, 2022
              <br>
              <a href="https://arxiv.org/abs/2010.07524">Paper</a>
              <p></p>
            </td>
          </tr>



          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="geovd.png" alt="geovd" width="240" height="120" style="border-style: none">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle>Geometry-Aware Deep Video Deblurring via Recurrent Feature Refinement</papertitle>
              <br><br>
              <strong>Taeoh Kim</strong>,
              Sangyoun Lee
              <br><br>
              <em>IEEE Transactions on Image Processing (TIP, IF 10.6)</em>, 2022
              <br>
              <a href="https://ieeexplore.ieee.org/document/9674805/">Paper</a>
              <p></p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="acn.png" alt="acn" width="240" height="80" style="border-style: none">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle>Enhanced Standard Compatible Image Compression Framework based on Auxiliary Codec Networks</papertitle>
              <br><br>
              Hanbin Son, <strong>Taeoh Kim</strong>, Hyeongmin Lee,
              Sangyoun Lee
              <br><br>
              <em>IEEE Transactions on Image Processing (TIP, IF 10.6)</em>, 2021
              <br>
              <a href="https://arxiv.org/pdf/2009.14754.pdf">Paper</a>
              <p></p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="spn.png" alt="spn" width="240" height="60" style="border-style: none">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle>Block-Attentive Subpixel Prediction Networks for Computationally Efficient Image Restoration</papertitle>
              <br><br>
              <strong>Taeoh Kim</strong>,
              Chajin Shin,
              Sangjin Lee,
              Sangyoun Lee
              <br><br>
              <em>IEEE Access (IF 3.367)</em>, 2021
              <br>
              <a href="https://ieeexplore.ieee.org/document/9464349">Paper</a>
              <p></p>
            </td>
          </tr>


          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="tta.png" alt="tta" width="240" height="140" style="border-style: none">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle>Test-Time Adaptation for Out-of-distributed Image Inpainting</papertitle>
              <br><br>
              Chajin Shin,
              <strong>Taeoh Kim</strong>,
              Sangjin Lee,
              Sangyoun Lee
              <br><br>
              <em>ICIP</em>, 2021
              <br>
              <a href="https://ieeexplore.ieee.org/document/9506461">Paper</a> /
              <a href="https://github.com/ChajinShin/AdaFill-Image_Inpainting">Code</a>
              <p></p>
            </td>
          </tr>




          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="aim.png" alt="aim" width="240" height="140" style="border-style: none">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle>AIM 2020 Challenge on Image Extreme Inpainting</papertitle>
              <br>
              <strong>2nd Place</strong> in the Image Inpainting Challenge Track 1: Classic Inpainting<br><br>
              Evangelos Ntavelis, AndrÂ´es Romero, Siavash Bigdeli, Radu Timofte, Zheng Hui, Xiumei Wang, Xinbo Gao, Chajin Shin,
              <strong>Taeoh Kim</strong>, Hanbin Son, Sangyoun Lee et al.
              <br><br>
              <em>ECCV Workshops (Advances in Image Manipulation (AIM))</em>, 2020
              <br>
              <a href="https://arxiv.org/abs/2010.01110">Paper</a>
              <p></p>
            </td>
          </tr>




          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="viprior.png" alt="viprior" width="240" height="130" style="border-style: none">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle>Learning Temporally Invariant and Localizable Features via Data Augmentation for Video Recognition</papertitle>
              <br>
              <strong>4th Place</strong> in the VIPriors Action Recognition Challenge<br><br>
              <strong>Taeoh Kim*</strong>,
              Hyeongmin Lee*, MyeongAh Cho*, Ho Seong Lee, Dong Heon Cho, Sangyoun Lee (*Equal Contribution)
              <br><br>
              <em>ECCV Workshops (1st Visual Inductive Priors (VIPriors) for Data-Efficient Deep Learning Workshop)</em>, 2020
              <br>
              <a href="https://arxiv.org/abs/2008.05721">Paper</a>
              <p></p>
            </td>
          </tr>



          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="rgm.png" alt="spn" width="240" height="130" style="border-style: none">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle>Relational Deep Feature Learning for Heterogeneous Face Recognition</papertitle>
              <br><br>
              MyeongAh Cho,
              <strong>Taeoh Kim</strong>,
              Ig-Jae Kim, Kyungjae Lee, Sangyoun Lee
              <br><br>
              <em>IEEE Transactions on Information Forensics and Security (IF 7.718)</em>, 2020
              <br>
              <a href="https://arxiv.org/abs/2003.00697">Paper</a>
              <p></p>
            </td>
          </tr>



          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="eic.png" alt="spn" width="240" height="130" style="border-style: none">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle>Extrapolative-Interpolative Cycle- Consistency Learning For Video Frame Extrapolation</papertitle>
              <br><br>
              Sangjin Lee, Hyeongmin Lee,
              <strong>Taeoh Kim</strong>, Sangyoun Lee
              <br><br>
              <em>ICIP</em>, 2020
              <br>
              <a href="https://arxiv.org/abs/2005.13194">Paper</a>
              <p></p>
            </td>
          </tr>



          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="adacof.png" alt="spn" width="240" height="130" style="border-style: none">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle>AdaCoF: Adaptive Collaboration of Flows for Video Frame Interpolation</papertitle>
              <br><br>
              Hyeongmin Lee,
              <strong>Taeoh Kim</strong>,
              Tae-Young Chung, Daehyun Pak, Yuseok Ban, Sangyoun Lee
              <br><br>
              <em>CVPR</em>, 2020
              <br>
              <a href="https://arxiv.org/abs/1907.10244">Paper</a> /
              <a href="https://github.com/HyeongminLEE/AdaCoF-pytorch">Code</a>
              <p></p>
            </td>
          </tr>



          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="tracking.png" alt="spn" width="240" height="130" style="border-style: none">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle>Sampling Operator to Learn the Scalable Correlation Filter for Visual Tracking</papertitle>
              <br><br>
              Minkyu Lee,
              <strong>Taeoh Kim</strong>, Yuseok Ban, Eungyeol Song, Sangyoun Lee
              <br><br>
              <em>IEEE Access (IF 3.367)</em>, 2019
              <br>
              <a href="https://ieeexplore.ieee.org/document/8613772">Paper</a>
              <p></p>
            </td>
          </tr>



            <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="sfcnn.png" alt="spn" width="240" height="100" style="border-style: none">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle>SF-CNN: A Fast Compression Artifacts Removal via Spatial-To-Frequency Convolutional Neural Networks</papertitle>
              <br><br>
              <strong>Taeoh Kim</strong>, Hyeongmin Lee, Hanbin Son, Sangyoun Lee
              <br><br>
              <em>ICIP</em>, 2019
              <br>
              <a href="https://ieeexplore.ieee.org/document/8803503">Paper</a>
              <p></p>
            </td>
          </tr>




          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="relationmodule.png" alt="spn" width="240" height="130" style="border-style: none">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle>NIR-to-VIS Face Recognition via Embedding Relations and Coordinates of the Pairwise Features</papertitle>
              <br><br>
              MyeongAh Cho, Tae-Young Chung,
              <strong>Taeoh Kim</strong>, Sangyoun Lee
              <br><br>
              <em>ICB</em>, 2019
              <br>
              <a href="https://ieeexplore.ieee.org/document/8987306">Paper</a>
              <p></p>
            </td>
          </tr>



                  <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="collabonet.png" alt="spn" width="240" height="60" style="border-style: none">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle>Collabonet: Collaboration of Generative Models by Unsupervised Classification</papertitle>
              <br><br>
              Hyeongmin Lee,
              <strong>Taeoh Kim</strong>, Eungyeol Song, Sangyoun Lee
              <br><br>
              <em>ICIP</em>, 2018
              <br>
              <a href="https://ieeexplore.ieee.org/document/8451825">Paper</a>
              <p></p>
            </td>
          </tr>




        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:right;font-size:small;">
                <a href="https://github.com/jonbarron/jonbarron_website">Source</a>
              </p>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>
</body>

</html>
