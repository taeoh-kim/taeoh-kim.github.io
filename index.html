
<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Taeoh Kim</title>
  
  <meta name="author" content="Taeoh Kim">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="style.css">
  <link rel="icon" type="image/png" href="images/seal_icon.png">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Taeoh Kim</name>
              </p>
              <p>I am a Research Engineer at <a href="https://clova.ai/">CLOVA</a> Vision, NAVER Corp.
              </p>
              <p>
                My research interests are Video Understanding and Representation Learning.
              </p>
              <p>I received my Ph. D. in Electrical and Electronic Engineering at Yonsei University under the supervision of <a href="http://mvp.yonsei.ac.kr/">Prof. Sangyoun Lee</a>.
              </p>
              <p>
                E-mail: taeoh.kim [at] navercorp.com
              </p>
              <p style="text-align:center">
                <a href="cv_taeohkim.pdf">CV</a> &nbsp/&nbsp   
                <a href="https://scholar.google.com/citations?user=mMgadisAAAAJ&hl=ko">Google Scholar</a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="taeoh.jpeg"><img style="width:100%;max-width:100%" alt="profile photo" src="taeoh.jpeg" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

        <h3>News!</h3>
        <p>
          [Nov 2022] One Paper is accepted to <strong>AAAI 2023</strong> (Video Representation Learning). <br>
          [Apr 2022] One Paper is accepted to <strong>Pattern Recognition</strong> (Video Anomaly Detection). <br>
          [Dec 2021] One Paper is accepted to <strong>IEEE Transactions on Image Processing</strong> (Video Deblurring). <br>
          [Nov 2021] One Paper is accepted to <strong>IEEE Transactions on Image Processing</strong> (Image Compression). <br>
          [Aug 2021] I joined Clova, NAVER Corp. as a Research Engineer. <br>
          [Aug 2021] I received my Ph. D. at Yonsei University.
              </p>
        <br>


        <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="freqaug.png" alt="freqaug" width="240" height="140" style="border-style: none">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle>Frequency Selective Augmentation for Video Representation Learning</papertitle>
              <br><br>
              Jinhyung Kim,
              <strong>Taeoh Kim</strong>, Minho Shim, Dongyoon Han, Dongyoon Wee,
              Junmo Kim
              <br><br>
              <em>AAAI</em>, 2023
              <br>
              <a href="https://arxiv.org/abs/2204.03865">Paper</a>
              <p></p>
            </td>
          </tr>


        <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="dynaaug.png" alt="dynaaug" width="240" height="140" style="border-style: none">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle>Exploring Temporally Dynamic Data Augmentation for Video Recognition</papertitle>
              <br><br>
              <strong>Taeoh Kim</strong>, Jinhyung Kim, Minho Shim, Sangdoo Yun, Myunggu Kang, Dongyoon Wee,
              Sangyoun Lee
              <br><br>
              <em>Arxiv Preprint</em>, 2022
              <br>
              <a href="https://arxiv.org/abs/2206.15015">Paper</a>
              <p></p>
            </td>
          </tr>



          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="flowano.png" alt="flowano" width="240" height="140" style="border-style: none">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle>Unsupervised Video Anomaly Detection via Normalizing Flows with Implicit Latent Features</papertitle>
              <br><br>
              MyeongAh Cho,
              <strong>Taeoh Kim</strong>, Woo Jin Kim, Suhwan Cho,
              Sangyoun Lee
              <br><br>
              <em>Pattern Recognition (PR, IF 7.74)</em>, 2022
              <br>
              <a href="https://arxiv.org/abs/2010.07524">Paper</a>
              <p></p>
            </td>
          </tr>



          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="geovd.png" alt="geovd" width="240" height="120" style="border-style: none">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle>Geometry-Aware Deep Video Deblurring via Recurrent Feature Refinement</papertitle>
              <br><br>
              <strong>Taeoh Kim</strong>,
              Sangyoun Lee
              <br><br>
              <em>IEEE Transactions on Image Processing (TIP, IF 10.856)</em>, 2022
              <br>
              <a href="https://ieeexplore.ieee.org/document/9674805/">Paper</a>
              <p></p>
            </td>
          </tr> 

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="acn.png" alt="acn" width="240" height="80" style="border-style: none">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle>Enhanced Standard Compatible Image Compression Framework based on Auxiliary Codec Networks</papertitle>
              <br><br>
              Hanbin Son, <strong>Taeoh Kim</strong>, Hyeongmin Lee,
              Sangyoun Lee
              <br><br>
              <em>IEEE Transactions on Image Processing (TIP, IF 10.856)</em>, 2021
              <br>
              <a href="https://arxiv.org/pdf/2009.14754.pdf">Paper</a>
              <p></p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="spn.png" alt="spn" width="240" height="60" style="border-style: none">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle>Block-Attentive Subpixel Prediction Networks for Computationally Efficient Image Restoration</papertitle>
              <br><br>
              <strong>Taeoh Kim</strong>,
              Chajin Shin,
              Sangjin Lee,
              Sangyoun Lee
              <br><br>
              <em>IEEE Access (IF 3.367)</em>, 2021
              <br>
              <a href="https://ieeexplore.ieee.org/document/9464349">Paper</a>
              <p></p>
            </td>
          </tr> 


          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="tta.png" alt="tta" width="240" height="140" style="border-style: none">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle>Test-Time Adaptation for Out-of-distributed Image Inpainting</papertitle>
              <br><br>
              Chajin Shin,
              <strong>Taeoh Kim</strong>,
              Sangjin Lee,
              Sangyoun Lee
              <br><br>
              <em>ICIP</em>, 2021
              <br>
              <a href="https://ieeexplore.ieee.org/document/9506461">Paper</a> /
              <a href="https://github.com/ChajinShin/AdaFill-Image_Inpainting">Code</a>
              <p></p>
            </td>
          </tr> 




          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="aim.png" alt="aim" width="240" height="140" style="border-style: none">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle>AIM 2020 Challenge on Image Extreme Inpainting</papertitle>
              <br>
              <strong>2nd Place</strong> in the Image Inpainting Challenge Track 1: Classic Inpainting<br><br>
              Evangelos Ntavelis, AndrÂ´es Romero, Siavash Bigdeli, Radu Timofte, Zheng Hui, Xiumei Wang, Xinbo Gao, Chajin Shin, 
              <strong>Taeoh Kim</strong>, Hanbin Son, Sangyoun Lee et al.
              <br><br>
              <em>ECCV Workshops (Advances in Image Manipulation (AIM))</em>, 2020
              <br>
              <a href="https://arxiv.org/abs/2010.01110">Paper</a>
              <p></p>
            </td>
          </tr> 




          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="viprior.png" alt="viprior" width="240" height="130" style="border-style: none">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle>Learning Temporally Invariant and Localizable Features via Data Augmentation for Video Recognition</papertitle>
              <br>
              <strong>4th Place</strong> in the VIPriors Action Recognition Challenge<br><br>
              <strong>Taeoh Kim*</strong>,
              Hyeongmin Lee*, MyeongAh Cho*, Ho Seong Lee, Dong Heon Cho, Sangyoun Lee (*Equal Contribution)
              <br><br>
              <em>ECCV Workshops (1st Visual Inductive Priors (VIPriors) for Data-Efficient Deep Learning Workshop)</em>, 2020
              <br>
              <a href="https://arxiv.org/abs/2008.05721">Paper</a>
              <p></p>
            </td>
          </tr>



          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="rgm.png" alt="spn" width="240" height="130" style="border-style: none">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle>Relational Deep Feature Learning for Heterogeneous Face Recognition</papertitle>
              <br><br>
              MyeongAh Cho,
              <strong>Taeoh Kim</strong>,
              Ig-Jae Kim, Kyungjae Lee, Sangyoun Lee
              <br><br>
              <em>IEEE Transactions on Information Forensics and Security (IF 7.718)</em>, 2020
              <br>
              <a href="https://arxiv.org/abs/2003.00697">Paper</a>
              <p></p>
            </td>
          </tr>



          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="eic.png" alt="spn" width="240" height="130" style="border-style: none">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle>Extrapolative-Interpolative Cycle- Consistency Learning For Video Frame Extrapolation</papertitle>
              <br><br>
              Sangjin Lee, Hyeongmin Lee,
              <strong>Taeoh Kim</strong>, Sangyoun Lee
              <br><br>
              <em>ICIP</em>, 2020
              <br>
              <a href="https://arxiv.org/abs/2005.13194">Paper</a>
              <p></p>
            </td>
          </tr>



          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="adacof.png" alt="spn" width="240" height="130" style="border-style: none">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle>AdaCoF: Adaptive Collaboration of Flows for Video Frame Interpolation</papertitle>
              <br><br>
              Hyeongmin Lee,
              <strong>Taeoh Kim</strong>,
              Tae-Young Chung, Daehyun Pak, Yuseok Ban, Sangyoun Lee
              <br><br>
              <em>CVPR</em>, 2020
              <br>
              <a href="https://arxiv.org/abs/1907.10244">Paper</a> /
              <a href="https://github.com/HyeongminLEE/AdaCoF-pytorch">Code</a>
              <p></p>
            </td>
          </tr>



          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="tracking.png" alt="spn" width="240" height="130" style="border-style: none">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle>Sampling Operator to Learn the Scalable Correlation Filter for Visual Tracking</papertitle>
              <br><br>
              Minkyu Lee,
              <strong>Taeoh Kim</strong>, Yuseok Ban, Eungyeol Song, Sangyoun Lee
              <br><br>
              <em>IEEE Access (IF 3.367)</em>, 2019
              <br>
              <a href="https://ieeexplore.ieee.org/document/8613772">Paper</a>
              <p></p>
            </td>
          </tr>



            <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="sfcnn.png" alt="spn" width="240" height="100" style="border-style: none">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle>SF-CNN: A Fast Compression Artifacts Removal via Spatial-To-Frequency Convolutional Neural Networks</papertitle>
              <br><br>
              <strong>Taeoh Kim</strong>, Hyeongmin Lee, Hanbin Son, Sangyoun Lee
              <br><br>
              <em>ICIP</em>, 2019
              <br>
              <a href="https://ieeexplore.ieee.org/document/8803503">Paper</a>
              <p></p>
            </td>
          </tr>




          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="relationmodule.png" alt="spn" width="240" height="130" style="border-style: none">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle>NIR-to-VIS Face Recognition via Embedding Relations and Coordinates of the Pairwise Features</papertitle>
              <br><br>
              MyeongAh Cho, Tae-Young Chung,
              <strong>Taeoh Kim</strong>, Sangyoun Lee
              <br><br>
              <em>ICB</em>, 2019
              <br>
              <a href="https://ieeexplore.ieee.org/document/8987306">Paper</a>
              <p></p>
            </td>
          </tr>



                  <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="collabonet.png" alt="spn" width="240" height="60" style="border-style: none">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle>Collabonet: Collaboration of Generative Models by Unsupervised Classification</papertitle>
              <br><br>
              Hyeongmin Lee,
              <strong>Taeoh Kim</strong>, Eungyeol Song, Sangyoun Lee
              <br><br>
              <em>ICIP</em>, 2018
              <br>
              <a href="https://ieeexplore.ieee.org/document/8451825">Paper</a>
              <p></p>
            </td>
          </tr>




        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:right;font-size:small;">
                <a href="https://github.com/jonbarron/jonbarron_website">Source</a> 
              </p>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>
</body>

</html>
